{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from verstack.stratified_continuous_split import scsplit # pip install verstack\n",
    "from sklearn import preprocessing\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neural_network import MLPRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the training data\n",
    "train_data = pd.read_csv(\"data/train_transformed.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "eva_data = pd.read_csv(\"data/evaluation_transformed.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>user_verified</th>\n",
       "      <th>user_statuses_count</th>\n",
       "      <th>user_followers_count</th>\n",
       "      <th>user_friends_count</th>\n",
       "      <th>ratio_friends_followers</th>\n",
       "      <th>mention_exist</th>\n",
       "      <th>mention_count</th>\n",
       "      <th>url_exist</th>\n",
       "      <th>url_count</th>\n",
       "      <th>...</th>\n",
       "      <th>tf_idf_0</th>\n",
       "      <th>tf_idf_1</th>\n",
       "      <th>tf_idf_2</th>\n",
       "      <th>tf_idf_3</th>\n",
       "      <th>tf_idf_4</th>\n",
       "      <th>tf_idf_5</th>\n",
       "      <th>tf_idf_6</th>\n",
       "      <th>tf_idf_7</th>\n",
       "      <th>tf_idf_8</th>\n",
       "      <th>tf_idf_9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>68460</td>\n",
       "      <td>1101</td>\n",
       "      <td>1226</td>\n",
       "      <td>1.112523</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.606137e-15</td>\n",
       "      <td>-1.992248e-13</td>\n",
       "      <td>-6.077335e-13</td>\n",
       "      <td>-1.726278e-12</td>\n",
       "      <td>7.402787e-13</td>\n",
       "      <td>2.375980e-14</td>\n",
       "      <td>2.692723e-13</td>\n",
       "      <td>5.657295e-13</td>\n",
       "      <td>-2.124336e-14</td>\n",
       "      <td>9.444088e-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>309</td>\n",
       "      <td>51</td>\n",
       "      <td>202</td>\n",
       "      <td>3.884615</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.206801e-02</td>\n",
       "      <td>2.715082e-03</td>\n",
       "      <td>1.318767e-02</td>\n",
       "      <td>3.157979e-02</td>\n",
       "      <td>2.662453e-02</td>\n",
       "      <td>1.621955e-02</td>\n",
       "      <td>-2.204838e-02</td>\n",
       "      <td>9.316040e-03</td>\n",
       "      <td>3.288260e-03</td>\n",
       "      <td>7.966161e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3241</td>\n",
       "      <td>1675</td>\n",
       "      <td>2325</td>\n",
       "      <td>1.387232</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.095493e-02</td>\n",
       "      <td>-1.131896e-03</td>\n",
       "      <td>3.852378e-02</td>\n",
       "      <td>1.163440e-01</td>\n",
       "      <td>1.542300e-01</td>\n",
       "      <td>2.938599e-01</td>\n",
       "      <td>4.018045e-01</td>\n",
       "      <td>1.909630e-01</td>\n",
       "      <td>3.218782e-01</td>\n",
       "      <td>-4.933187e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>32327</td>\n",
       "      <td>667</td>\n",
       "      <td>304</td>\n",
       "      <td>0.455090</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>8.873053e-03</td>\n",
       "      <td>1.403727e-03</td>\n",
       "      <td>3.399734e-03</td>\n",
       "      <td>1.401861e-02</td>\n",
       "      <td>9.761796e-03</td>\n",
       "      <td>9.215406e-03</td>\n",
       "      <td>6.693422e-03</td>\n",
       "      <td>8.483338e-03</td>\n",
       "      <td>-2.502589e-03</td>\n",
       "      <td>1.261141e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>581</td>\n",
       "      <td>42</td>\n",
       "      <td>127</td>\n",
       "      <td>2.953488</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.774364e-02</td>\n",
       "      <td>-1.756079e-03</td>\n",
       "      <td>8.245230e-03</td>\n",
       "      <td>3.155745e-02</td>\n",
       "      <td>1.385880e-02</td>\n",
       "      <td>5.119571e-03</td>\n",
       "      <td>3.617241e-03</td>\n",
       "      <td>1.908667e-02</td>\n",
       "      <td>-1.212654e-02</td>\n",
       "      <td>1.883319e-02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  user_verified  user_statuses_count  user_followers_count  \\\n",
       "0   0              0                68460                  1101   \n",
       "1   1              0                  309                    51   \n",
       "2   2              0                 3241                  1675   \n",
       "3   3              0                32327                   667   \n",
       "4   4              0                  581                    42   \n",
       "\n",
       "   user_friends_count  ratio_friends_followers  mention_exist  mention_count  \\\n",
       "0                1226                 1.112523              0              0   \n",
       "1                 202                 3.884615              0              0   \n",
       "2                2325                 1.387232              0              0   \n",
       "3                 304                 0.455090              0              0   \n",
       "4                 127                 2.953488              0              0   \n",
       "\n",
       "   url_exist  url_count  ...      tf_idf_0      tf_idf_1      tf_idf_2  \\\n",
       "0          0          0  ... -1.606137e-15 -1.992248e-13 -6.077335e-13   \n",
       "1          0          0  ...  1.206801e-02  2.715082e-03  1.318767e-02   \n",
       "2          0          0  ...  5.095493e-02 -1.131896e-03  3.852378e-02   \n",
       "3          0          0  ...  8.873053e-03  1.403727e-03  3.399734e-03   \n",
       "4          0          0  ...  2.774364e-02 -1.756079e-03  8.245230e-03   \n",
       "\n",
       "       tf_idf_3      tf_idf_4      tf_idf_5      tf_idf_6      tf_idf_7  \\\n",
       "0 -1.726278e-12  7.402787e-13  2.375980e-14  2.692723e-13  5.657295e-13   \n",
       "1  3.157979e-02  2.662453e-02  1.621955e-02 -2.204838e-02  9.316040e-03   \n",
       "2  1.163440e-01  1.542300e-01  2.938599e-01  4.018045e-01  1.909630e-01   \n",
       "3  1.401861e-02  9.761796e-03  9.215406e-03  6.693422e-03  8.483338e-03   \n",
       "4  3.155745e-02  1.385880e-02  5.119571e-03  3.617241e-03  1.908667e-02   \n",
       "\n",
       "       tf_idf_8      tf_idf_9  \n",
       "0 -2.124336e-14  9.444088e-14  \n",
       "1  3.288260e-03  7.966161e-02  \n",
       "2  3.218782e-01 -4.933187e-02  \n",
       "3 -2.502589e-03  1.261141e-02  \n",
       "4 -1.212654e-02  1.883319e-02  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scsplit method is used in order to split our regression data in a stratisfied way and keep a similar distribution of retweet counts between the two sets\n",
    "X_train_all, X_test_all, y_train, y_test = scsplit(train_data, train_data['retweet_count'], stratify=train_data['retweet_count'], train_size=0.7, test_size=0.3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>user_verified</th>\n",
       "      <th>user_statuses_count</th>\n",
       "      <th>user_followers_count</th>\n",
       "      <th>user_friends_count</th>\n",
       "      <th>ratio_friends_followers</th>\n",
       "      <th>mention_exist</th>\n",
       "      <th>mention_count</th>\n",
       "      <th>url_exist</th>\n",
       "      <th>url_count</th>\n",
       "      <th>...</th>\n",
       "      <th>tf_idf_0</th>\n",
       "      <th>tf_idf_1</th>\n",
       "      <th>tf_idf_2</th>\n",
       "      <th>tf_idf_3</th>\n",
       "      <th>tf_idf_4</th>\n",
       "      <th>tf_idf_5</th>\n",
       "      <th>tf_idf_6</th>\n",
       "      <th>tf_idf_7</th>\n",
       "      <th>tf_idf_8</th>\n",
       "      <th>tf_idf_9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>621957</th>\n",
       "      <td>621957</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.383191</td>\n",
       "      <td>-0.095283</td>\n",
       "      <td>-0.041342</td>\n",
       "      <td>0.692170</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.231249</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.675342</td>\n",
       "      <td>...</td>\n",
       "      <td>0.658434</td>\n",
       "      <td>0.725856</td>\n",
       "      <td>0.077128</td>\n",
       "      <td>-0.108096</td>\n",
       "      <td>-0.051642</td>\n",
       "      <td>-0.033000</td>\n",
       "      <td>-0.013369</td>\n",
       "      <td>-0.057080</td>\n",
       "      <td>0.011628</td>\n",
       "      <td>-0.060725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>479798</th>\n",
       "      <td>479798</td>\n",
       "      <td>0</td>\n",
       "      <td>0.061909</td>\n",
       "      <td>-0.081055</td>\n",
       "      <td>0.021332</td>\n",
       "      <td>-0.214172</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.231249</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.675342</td>\n",
       "      <td>...</td>\n",
       "      <td>0.346298</td>\n",
       "      <td>-0.413063</td>\n",
       "      <td>0.801847</td>\n",
       "      <td>0.144007</td>\n",
       "      <td>-0.157371</td>\n",
       "      <td>-0.071168</td>\n",
       "      <td>-0.013226</td>\n",
       "      <td>-0.057253</td>\n",
       "      <td>-0.023296</td>\n",
       "      <td>-0.057848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>312849</th>\n",
       "      <td>312849</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.309820</td>\n",
       "      <td>-0.095253</td>\n",
       "      <td>-0.152957</td>\n",
       "      <td>-0.131321</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.231249</td>\n",
       "      <td>1</td>\n",
       "      <td>1.364308</td>\n",
       "      <td>...</td>\n",
       "      <td>0.652465</td>\n",
       "      <td>-0.185419</td>\n",
       "      <td>-0.523064</td>\n",
       "      <td>0.404621</td>\n",
       "      <td>-0.213981</td>\n",
       "      <td>-0.070115</td>\n",
       "      <td>-0.037405</td>\n",
       "      <td>-0.147147</td>\n",
       "      <td>0.086430</td>\n",
       "      <td>-0.065926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321181</th>\n",
       "      <td>321181</td>\n",
       "      <td>0</td>\n",
       "      <td>0.500588</td>\n",
       "      <td>-0.094681</td>\n",
       "      <td>-0.036910</td>\n",
       "      <td>-0.092401</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.231249</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.675342</td>\n",
       "      <td>...</td>\n",
       "      <td>0.037329</td>\n",
       "      <td>0.002418</td>\n",
       "      <td>0.003632</td>\n",
       "      <td>0.057988</td>\n",
       "      <td>0.024457</td>\n",
       "      <td>0.040928</td>\n",
       "      <td>0.017294</td>\n",
       "      <td>0.041428</td>\n",
       "      <td>-0.017589</td>\n",
       "      <td>0.174764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336415</th>\n",
       "      <td>336415</td>\n",
       "      <td>0</td>\n",
       "      <td>0.161973</td>\n",
       "      <td>-0.092153</td>\n",
       "      <td>-0.147276</td>\n",
       "      <td>-0.218517</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.231249</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.675342</td>\n",
       "      <td>...</td>\n",
       "      <td>0.024330</td>\n",
       "      <td>0.002255</td>\n",
       "      <td>0.007894</td>\n",
       "      <td>0.027406</td>\n",
       "      <td>0.015418</td>\n",
       "      <td>0.020338</td>\n",
       "      <td>0.002823</td>\n",
       "      <td>0.076444</td>\n",
       "      <td>-0.018720</td>\n",
       "      <td>0.186460</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id  user_verified  user_statuses_count  user_followers_count  \\\n",
       "621957  621957              0            -0.383191             -0.095283   \n",
       "479798  479798              0             0.061909             -0.081055   \n",
       "312849  312849              0            -0.309820             -0.095253   \n",
       "321181  321181              0             0.500588             -0.094681   \n",
       "336415  336415              0             0.161973             -0.092153   \n",
       "\n",
       "        user_friends_count  ratio_friends_followers  mention_exist  \\\n",
       "621957           -0.041342                 0.692170              0   \n",
       "479798            0.021332                -0.214172              0   \n",
       "312849           -0.152957                -0.131321              0   \n",
       "321181           -0.036910                -0.092401              0   \n",
       "336415           -0.147276                -0.218517              0   \n",
       "\n",
       "        mention_count  url_exist  url_count  ...  tf_idf_0  tf_idf_1  \\\n",
       "621957      -0.231249          0  -0.675342  ...  0.658434  0.725856   \n",
       "479798      -0.231249          0  -0.675342  ...  0.346298 -0.413063   \n",
       "312849      -0.231249          1   1.364308  ...  0.652465 -0.185419   \n",
       "321181      -0.231249          0  -0.675342  ...  0.037329  0.002418   \n",
       "336415      -0.231249          0  -0.675342  ...  0.024330  0.002255   \n",
       "\n",
       "        tf_idf_2  tf_idf_3  tf_idf_4  tf_idf_5  tf_idf_6  tf_idf_7  tf_idf_8  \\\n",
       "621957  0.077128 -0.108096 -0.051642 -0.033000 -0.013369 -0.057080  0.011628   \n",
       "479798  0.801847  0.144007 -0.157371 -0.071168 -0.013226 -0.057253 -0.023296   \n",
       "312849 -0.523064  0.404621 -0.213981 -0.070115 -0.037405 -0.147147  0.086430   \n",
       "321181  0.003632  0.057988  0.024457  0.040928  0.017294  0.041428 -0.017589   \n",
       "336415  0.007894  0.027406  0.015418  0.020338  0.002823  0.076444 -0.018720   \n",
       "\n",
       "        tf_idf_9  \n",
       "621957 -0.060725  \n",
       "479798 -0.057848  \n",
       "312849 -0.065926  \n",
       "321181  0.174764  \n",
       "336415  0.186460  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_need_scaled=['user_statuses_count', 'user_followers_count', 'user_friends_count', 'ratio_friends_followers', 'mention_count','url_count', 'hashtag_count', 'text_length']\n",
    "scaler = preprocessing.StandardScaler()\n",
    "scaler.fit(X_train_all[features_need_scaled])\n",
    "X_train_all[features_need_scaled] = scaler.transform(X_train_all[features_need_scaled])\n",
    "X_test_all[features_need_scaled] = scaler.transform(X_test_all[features_need_scaled])\n",
    "eva_data[features_need_scaled] = scaler.transform(eva_data[features_need_scaled])\n",
    "X_train_all.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-layer perceptron enhanced random forest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlp_rf(X_train, y_train, random_state, hidden_layer_sizes, batch_size, max_depth, n_estimators):\n",
    "    \n",
    "    # MLP部分\n",
    "    mlp = MLPRegressor(random_state= 77,  \n",
    "                        hidden_layer_sizes= hidden_layer_sizes,  \n",
    "                        batch_size= batch_size,  \n",
    "                        learning_rate_init=.01,\n",
    "                        early_stopping=False,\n",
    "                        verbose=True,\n",
    "                        shuffle=True,\n",
    "                        n_iter_no_change=10)\n",
    "    \n",
    "    y_train_log = np.log(y_train+1)\n",
    "    \n",
    "    mlp.fit(X_train, y_train_log) \n",
    "    \n",
    "    mlp_y_train_predict = mlp.predict(X_train) # this produces a ndarray\n",
    "    print(\"Prediction error:\", mean_absolute_error(y_true=y_test, y_pred = np.exp(mlp.predict(X_test))-1 ))\n",
    "    \n",
    "    # 随机森林部分\n",
    "    # for training residual RF\n",
    "    rf_y_train = y_train_log - mlp_y_train_predict\n",
    "    \n",
    "    reg = RandomForestRegressor(max_depth = max_depth,   \n",
    "                                n_estimators = n_estimators, \n",
    "                                random_state = 7,  \n",
    "                                n_jobs = 10, \n",
    "                                verbose = 5)  \n",
    "\n",
    "    reg.fit(X_train, rf_y_train)\n",
    "    return mlp, reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_selected=['user_verified', 'user_statuses_count', 'user_followers_count',\n",
    "                 'user_friends_count', 'ratio_friends_followers', 'mention_exist',\n",
    "                 'mention_count', 'url_exist', 'url_count', 'hashtag_exist',\n",
    "                 'hashtag_count', 'weekend', 'text_length', 'sentiment_pos', \n",
    "                 'sentiment_neg', 'sentiment_neu', 'tf_idf_0', 'tf_idf_1', 'tf_idf_2'] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits = 5, shuffle = True, random_state = 43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object _BaseKFold.split at 0x000002CA4965A9C8>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KFold(5, shuffle = True, random_state = 43).split(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_data[features_selected]\n",
    "y_train = train_data['retweet_count']\n",
    "eval_data = pd.read_csv(\"data/evaluation_transformed.csv\")\n",
    "X_val = eval_data[features_selected]\n",
    "\n",
    "\n",
    "features_need_scaled=['user_statuses_count', 'user_followers_count', 'user_friends_count', 'ratio_friends_followers', 'mention_count','url_count', 'hashtag_count', 'text_length']\n",
    "scaler = preprocessing.StandardScaler()\n",
    "scaler.fit(X_train[features_need_scaled])\n",
    "X_train[features_need_scaled] = scaler.transform(X_train[features_need_scaled])\n",
    "X_val[features_need_scaled] = scaler.transform(X_val[features_need_scaled])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.58280993\n",
      "Iteration 2, loss = 0.54012431\n",
      "Iteration 3, loss = 0.53117392\n",
      "Iteration 4, loss = 0.52751973\n",
      "Iteration 5, loss = 0.52695528\n",
      "Iteration 6, loss = 0.52305152\n",
      "Iteration 7, loss = 0.52090465\n",
      "Iteration 8, loss = 0.51890148\n",
      "Iteration 9, loss = 0.51895809\n",
      "Iteration 10, loss = 0.51742144\n",
      "Iteration 11, loss = 0.51572674\n",
      "Iteration 12, loss = 0.51475043\n",
      "Iteration 13, loss = 0.51310208\n",
      "Iteration 14, loss = 0.51176104\n",
      "Iteration 15, loss = 0.51085639\n",
      "Iteration 16, loss = 0.51081340\n",
      "Iteration 17, loss = 0.51084512\n",
      "Iteration 18, loss = 0.50960153\n",
      "Iteration 19, loss = 0.51003399\n",
      "Iteration 20, loss = 0.51020377\n",
      "Iteration 21, loss = 0.50773390\n",
      "Iteration 22, loss = 0.50821287\n",
      "Iteration 23, loss = 0.50781050\n",
      "Iteration 24, loss = 0.50649050\n",
      "Iteration 25, loss = 0.50609081\n",
      "Iteration 26, loss = 0.50546725\n",
      "Iteration 27, loss = 0.50535102\n",
      "Iteration 28, loss = 0.50552186\n",
      "Iteration 29, loss = 0.50475888\n",
      "Iteration 30, loss = 0.50396550\n",
      "Iteration 31, loss = 0.50361109\n",
      "Iteration 32, loss = 0.50348779\n",
      "Iteration 33, loss = 0.50377743\n",
      "Iteration 34, loss = 0.50316760\n",
      "Iteration 35, loss = 0.50253326\n",
      "Iteration 36, loss = 0.50313451\n",
      "Iteration 37, loss = 0.50230988\n",
      "Iteration 38, loss = 0.50240406\n",
      "Iteration 39, loss = 0.50164565\n",
      "Iteration 40, loss = 0.50174847\n",
      "Iteration 41, loss = 0.50133856\n",
      "Iteration 42, loss = 0.50047542\n",
      "Iteration 43, loss = 0.50140372\n",
      "Iteration 44, loss = 0.50168840\n",
      "Iteration 45, loss = 0.50041402\n",
      "Iteration 46, loss = 0.49947241\n",
      "Iteration 47, loss = 0.50016490\n",
      "Iteration 48, loss = 0.50040810\n",
      "Iteration 49, loss = 0.49990875\n",
      "Iteration 50, loss = 0.49876334\n",
      "Iteration 51, loss = 0.49859154\n",
      "Iteration 52, loss = 0.49911249\n",
      "Iteration 53, loss = 0.49909398\n",
      "Iteration 54, loss = 0.49927229\n",
      "Iteration 55, loss = 0.49847239\n",
      "Iteration 56, loss = 0.49879992\n",
      "Iteration 57, loss = 0.49809113\n",
      "Iteration 58, loss = 0.49861078\n",
      "Iteration 59, loss = 0.49943192\n",
      "Iteration 60, loss = 0.49891401\n",
      "Iteration 61, loss = 0.49826879\n",
      "Iteration 62, loss = 0.49835073\n",
      "Iteration 63, loss = 0.49811177\n",
      "Iteration 64, loss = 0.49868313\n",
      "Iteration 65, loss = 0.49801152\n",
      "Iteration 66, loss = 0.49837152\n",
      "Iteration 67, loss = 0.49803639\n",
      "Iteration 68, loss = 0.49763775\n",
      "Iteration 69, loss = 0.49738474\n",
      "Iteration 70, loss = 0.49725234\n",
      "Iteration 71, loss = 0.49747615\n",
      "Iteration 72, loss = 0.49824565\n",
      "Iteration 73, loss = 0.49789152\n",
      "Iteration 74, loss = 0.49707325\n",
      "Iteration 75, loss = 0.49647262\n"
     ]
    }
   ],
   "source": [
    "results_cv=[]\n",
    "\n",
    "for train_index, test_index in kf.split(np.array(X_train)):\n",
    "    X_train_tmp, X_test_tmp = pd.DataFrame(np.array(X_train)[train_index]), pd.DataFrame(np.array(X_train)[test_index])\n",
    "    y_train_tmp, y_test_tmp = y_train[train_index], y_train[test_index]\n",
    "    mlp, reg = mlp_rf(X_train_tmp, y_train_tmp, 41, (128,64,32,8), 512, 18, 100)\n",
    "    \n",
    "    mlp_predict_y_log = mlp.predict(X_test_tmp)\n",
    "\n",
    "    rf_predict_y_log = reg.predict(X_test_tmp)\n",
    "\n",
    "    y_predict = np.exp(mlp_predict_y_log + rf_predict_y_log) -1\n",
    "\n",
    "    print(mean_absolute_error(y_test_tmp, y_predict))\n",
    "    results_cv.append(mean_absolute_error(y_test_tmp, y_predict))\n",
    "print(results_cv.mean())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
