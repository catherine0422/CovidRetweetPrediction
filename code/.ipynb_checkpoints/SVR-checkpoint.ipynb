{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from verstack.stratified_continuous_split import scsplit # pip install verstack\n",
    "from sklearn.svm import SVR, LinearSVR\n",
    "from sklearn.kernel_approximation import Nystroem\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data pre-precess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the training data\n",
    "train_data = pd.read_csv(\"../data/train_transformed.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>user_verified</th>\n",
       "      <th>user_statuses_count</th>\n",
       "      <th>user_followers_count</th>\n",
       "      <th>user_friends_count</th>\n",
       "      <th>ratio_friends_followers</th>\n",
       "      <th>mention_exist</th>\n",
       "      <th>mention_count</th>\n",
       "      <th>url_exist</th>\n",
       "      <th>url_count</th>\n",
       "      <th>...</th>\n",
       "      <th>tf_idf_0</th>\n",
       "      <th>tf_idf_1</th>\n",
       "      <th>tf_idf_2</th>\n",
       "      <th>tf_idf_3</th>\n",
       "      <th>tf_idf_4</th>\n",
       "      <th>tf_idf_5</th>\n",
       "      <th>tf_idf_6</th>\n",
       "      <th>tf_idf_7</th>\n",
       "      <th>tf_idf_8</th>\n",
       "      <th>tf_idf_9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>68460</td>\n",
       "      <td>1101</td>\n",
       "      <td>1226</td>\n",
       "      <td>1.112523</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.606137e-15</td>\n",
       "      <td>-1.992248e-13</td>\n",
       "      <td>-6.077335e-13</td>\n",
       "      <td>-1.726278e-12</td>\n",
       "      <td>7.402787e-13</td>\n",
       "      <td>2.375980e-14</td>\n",
       "      <td>2.692723e-13</td>\n",
       "      <td>5.657295e-13</td>\n",
       "      <td>-2.124336e-14</td>\n",
       "      <td>9.444088e-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>309</td>\n",
       "      <td>51</td>\n",
       "      <td>202</td>\n",
       "      <td>3.884615</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.206801e-02</td>\n",
       "      <td>2.715082e-03</td>\n",
       "      <td>1.318767e-02</td>\n",
       "      <td>3.157979e-02</td>\n",
       "      <td>2.662453e-02</td>\n",
       "      <td>1.621955e-02</td>\n",
       "      <td>-2.204838e-02</td>\n",
       "      <td>9.316040e-03</td>\n",
       "      <td>3.288260e-03</td>\n",
       "      <td>7.966161e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3241</td>\n",
       "      <td>1675</td>\n",
       "      <td>2325</td>\n",
       "      <td>1.387232</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.095493e-02</td>\n",
       "      <td>-1.131896e-03</td>\n",
       "      <td>3.852378e-02</td>\n",
       "      <td>1.163440e-01</td>\n",
       "      <td>1.542300e-01</td>\n",
       "      <td>2.938599e-01</td>\n",
       "      <td>4.018045e-01</td>\n",
       "      <td>1.909630e-01</td>\n",
       "      <td>3.218782e-01</td>\n",
       "      <td>-4.933187e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>32327</td>\n",
       "      <td>667</td>\n",
       "      <td>304</td>\n",
       "      <td>0.455090</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>8.873053e-03</td>\n",
       "      <td>1.403727e-03</td>\n",
       "      <td>3.399734e-03</td>\n",
       "      <td>1.401861e-02</td>\n",
       "      <td>9.761796e-03</td>\n",
       "      <td>9.215406e-03</td>\n",
       "      <td>6.693422e-03</td>\n",
       "      <td>8.483338e-03</td>\n",
       "      <td>-2.502589e-03</td>\n",
       "      <td>1.261141e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>581</td>\n",
       "      <td>42</td>\n",
       "      <td>127</td>\n",
       "      <td>2.953488</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.774364e-02</td>\n",
       "      <td>-1.756079e-03</td>\n",
       "      <td>8.245230e-03</td>\n",
       "      <td>3.155745e-02</td>\n",
       "      <td>1.385880e-02</td>\n",
       "      <td>5.119571e-03</td>\n",
       "      <td>3.617241e-03</td>\n",
       "      <td>1.908667e-02</td>\n",
       "      <td>-1.212654e-02</td>\n",
       "      <td>1.883319e-02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  user_verified  user_statuses_count  user_followers_count  \\\n",
       "0   0              0                68460                  1101   \n",
       "1   1              0                  309                    51   \n",
       "2   2              0                 3241                  1675   \n",
       "3   3              0                32327                   667   \n",
       "4   4              0                  581                    42   \n",
       "\n",
       "   user_friends_count  ratio_friends_followers  mention_exist  mention_count  \\\n",
       "0                1226                 1.112523              0              0   \n",
       "1                 202                 3.884615              0              0   \n",
       "2                2325                 1.387232              0              0   \n",
       "3                 304                 0.455090              0              0   \n",
       "4                 127                 2.953488              0              0   \n",
       "\n",
       "   url_exist  url_count  ...      tf_idf_0      tf_idf_1      tf_idf_2  \\\n",
       "0          0          0  ... -1.606137e-15 -1.992248e-13 -6.077335e-13   \n",
       "1          0          0  ...  1.206801e-02  2.715082e-03  1.318767e-02   \n",
       "2          0          0  ...  5.095493e-02 -1.131896e-03  3.852378e-02   \n",
       "3          0          0  ...  8.873053e-03  1.403727e-03  3.399734e-03   \n",
       "4          0          0  ...  2.774364e-02 -1.756079e-03  8.245230e-03   \n",
       "\n",
       "       tf_idf_3      tf_idf_4      tf_idf_5      tf_idf_6      tf_idf_7  \\\n",
       "0 -1.726278e-12  7.402787e-13  2.375980e-14  2.692723e-13  5.657295e-13   \n",
       "1  3.157979e-02  2.662453e-02  1.621955e-02 -2.204838e-02  9.316040e-03   \n",
       "2  1.163440e-01  1.542300e-01  2.938599e-01  4.018045e-01  1.909630e-01   \n",
       "3  1.401861e-02  9.761796e-03  9.215406e-03  6.693422e-03  8.483338e-03   \n",
       "4  3.155745e-02  1.385880e-02  5.119571e-03  3.617241e-03  1.908667e-02   \n",
       "\n",
       "       tf_idf_8      tf_idf_9  \n",
       "0 -2.124336e-14  9.444088e-14  \n",
       "1  3.288260e-03  7.966161e-02  \n",
       "2  3.218782e-01 -4.933187e-02  \n",
       "3 -2.502589e-03  1.261141e-02  \n",
       "4 -1.212654e-02  1.883319e-02  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scsplit method is used in order to split our regression data in a stratisfied way and keep a similar distribution of retweet counts between the two sets\n",
    "X_train_all, X_test_all, y_train, y_test = scsplit(train_data, train_data['retweet_count'], stratify=train_data['retweet_count'], train_size=0.7, test_size=0.3)\n",
    "features_need_scaled=['user_statuses_count', 'user_followers_count', 'user_friends_count', 'ratio_friends_followers', 'mention_count','url_count', 'hashtag_count', 'text_length']\n",
    "scaler = preprocessing.StandardScaler()\n",
    "scaler.fit(X_train_all[features_need_scaled])\n",
    "X_train_all[features_need_scaled] = scaler.transform(X_train_all[features_need_scaled])\n",
    "X_test_all[features_need_scaled] = scaler.transform(X_test_all[features_need_scaled])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['id', 'user_verified', 'user_statuses_count', 'user_followers_count', 'user_friends_count', 'ratio_friends_followers', 'mention_exist', 'mention_count', 'url_exist', 'url_count', 'hashtag_exist', 'hashtag_count', 'timeseg', 'weekend', 'day_of_week', 'text_length', 'sentiment_pos', 'sentiment_neg', 'sentiment_neu', 'sentiment_comp', 'retweet_count', 'tf_idf_0', 'tf_idf_1', 'tf_idf_2', 'tf_idf_3', 'tf_idf_4', 'tf_idf_5', 'tf_idf_6', 'tf_idf_7', 'tf_idf_8', 'tf_idf_9']\n"
     ]
    }
   ],
   "source": [
    "print(train_data.columns.values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'features_number' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-66b9d48c27ea>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mX_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_features_set\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_all\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeatures_number\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mX_test\u001b[0m \u001b[1;33m=\u001b[0m  \u001b[0mget_features_set\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test_all\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeatures_number\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'features_number' is not defined"
     ]
    }
   ],
   "source": [
    "X_train = get_features_set(X_train_all, features_number)\n",
    "X_test =  get_features_set(X_test_all, features_number )\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MODEL\n",
    "\n",
    "###  1) SVR\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  1.1 LinearSVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import random\n",
    "# random.seed( 10 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linearsvr_predict(X_train, y_train,X_test):\n",
    "    clf = LinearSVR()\n",
    "    clf.fit(X_train, y_train)\n",
    "    return clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction error rbf: 149.59138899946052\n"
     ]
    }
   ],
   "source": [
    "y_test_pre=linearsvr_predict(X_train, y_train,X_test)\n",
    "print(\"Prediction error rbf:\", mean_absolute_error(y_true=y_test, y_pred=y_test_pre))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=get_features_set(train_data, features_number)\n",
    "y_train = train_data['retweet_count']\n",
    "eval_data = pd.read_csv(\"data/evaluation_transformed.csv\")\n",
    "X_val = get_features_set(eval_data, features_number)\n",
    "\n",
    "features_need_scaled=['user_statuses_count', 'user_followers_count', 'user_friends_count', 'ratio_friends_followers', 'mention_count','url_count', 'hashtag_count', 'text_length']\n",
    "scaler = preprocessing.StandardScaler()\n",
    "scaler.fit(X_train[features_need_scaled])\n",
    "X_train[features_need_scaled] = scaler.transform(X_train[features_need_scaled])\n",
    "X_val[features_need_scaled] = scaler.transform(X_val[features_need_scaled])\n",
    "\n",
    "\n",
    "y_pred = linearsvr_predict(X_train,y_train,X_val) #################\n",
    "\n",
    "# Dump the results into a file that follows the required Kaggle template\n",
    "with open(\"prediction/svr_predictions.csv\", 'w') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow([\"TweetID\", \"NoRetweets\"])\n",
    "    for index, prediction in enumerate(y_pred):\n",
    "        writer.writerow([str(eval_data['id'].iloc[index]) , str(int(prediction))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scsplit method is used in order to split our regression data in a stratisfied way and keep a similar distribution of retweet counts between the two sets\n",
    "X_train_all, X_test_all, y_train, y_test = scsplit(train_data, train_data['retweet_count'], stratify=train_data['retweet_count'], train_size=0.7, test_size=0.3)\n",
    "features_need_scaled=['user_statuses_count', 'user_followers_count', 'user_friends_count', 'ratio_friends_followers', 'mention_count','url_count', 'hashtag_count', 'text_length']\n",
    "scaler = preprocessing.StandardScaler()\n",
    "scaler.fit(X_train_all[features_need_scaled])\n",
    "X_train_all[features_need_scaled] = scaler.transform(X_train_all[features_need_scaled])\n",
    "X_test_all[features_need_scaled] = scaler.transform(X_test_all[features_need_scaled])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train=np.log(y_train+1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "586559    0.000000\n",
      "457018    0.000000\n",
      "531302    0.000000\n",
      "618471    5.023881\n",
      "514798    0.000000\n",
      "            ...   \n",
      "192556    4.356709\n",
      "508243    0.000000\n",
      "166437    0.693147\n",
      "284126    2.079442\n",
      "183462    0.000000\n",
      "Name: retweet_count, Length: 466043, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svr(features_selected):\n",
    "    X_train = X_train_all[features_selected]\n",
    "    X_test = X_test_all[features_selected]\n",
    "    svr = LinearSVR()\n",
    "    svr.fit(X_train, y_train)\n",
    "    y_pred = svr.predict(X_test)\n",
    "    print(\"Prediction error:\", mean_absolute_error(y_true=y_test, y_pred=np.exp(y_pred)-1))\n",
    "    \n",
    "#     # Plot the feature importances\n",
    "#     index_sort = np.argsort(svr.coef_)[::-1]\n",
    "#     plt.figure(figsize=[15,5])\n",
    "#     plt.plot(X_train.columns[index_sort], svr.coef_[index_sort])\n",
    "#     plt.xticks(rotation='vertical')\n",
    "#     plt.xlabel('importances')\n",
    "#     plt.ylabel('features')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction error: 11171725.840050265\n"
     ]
    }
   ],
   "source": [
    "# features_selected=['user_verified', 'user_statuses_count', 'user_followers_count',\n",
    "#                  'user_friends_count', 'ratio_friends_followers', 'mention_exist',\n",
    "#                  'mention_count', 'url_exist', 'url_count', 'hashtag_exist',\n",
    "#                  'hashtag_count', 'weekend', 'text_length', 'sentiment_pos', \n",
    "#                  'sentiment_neg', 'sentiment_neu', 'tf_idf_0', 'tf_idf_1', 'tf_idf_2'] #149.59138899946052\n",
    "\n",
    "#features_selected = ['user_friends_count', 'tf_idf_0', 'tf_idf_1', 'tf_idf_2']  # 149.36232108140808\n",
    "\n",
    "features_selected=['user_statuses_count', 'user_followers_count',\n",
    "                 'user_friends_count', 'ratio_friends_followers', 'text_length', 'sentiment_pos', \n",
    "                 'sentiment_neg', 'sentiment_neu', 'tf_idf_0', 'tf_idf_1', 'tf_idf_2'] #148.30077890040835\n",
    "svr(features_selected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
