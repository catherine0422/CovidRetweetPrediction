{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "from sklearn.decomposition import TruncatedSVD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extraction of features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Definition of functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Extraction of user features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the user features\n",
    "def extract_user_features(data_origin, data_transformed):\n",
    "    print('extracting user features')\n",
    "    # user_verified: 1 or 0 to denote whether the user has been verified by Twitter\n",
    "    # change the boolean value into 1(for true) or 0(for faulse)\n",
    "    data_transformed['user_verified'] = data_origin['user_verified'].astype(int)\n",
    "\n",
    "    # user_statuses_count: The total number of tweets (statuses) the user has published\n",
    "    data_transformed['user_statuses_count'] = data_origin['user_statuses_count'].astype(int)\n",
    "\n",
    "    # user_followers_count: The number of followers the user has\n",
    "    data_transformed['user_followers_count'] = data_origin['user_followers_count'].astype(int)\n",
    "\n",
    "    # user_friends_count: The number of friends the user has\n",
    "    data_transformed['user_friends_count'] = data_origin['user_friends_count'].astype(int)\n",
    "\n",
    "    # ratio_friends_followers: ratio of No. of friends and No. of followers\n",
    "    data_transformed['ratio_friends_followers'] = data_origin[\"user_friends_count\"] / (data_origin[\"user_followers_count\"] + 1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Extraction of tweet features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the tweet features\n",
    "def extract_tweet_features(data_origin, data_transformed):\n",
    "    print('extracting tweet features')\n",
    "    # mention_exist: 1 or 0 to denote whether a tweet mentions other users\n",
    "    data_transformed['mention_exist'] = 1 - data_origin['user_mentions'].isna().astype(int)\n",
    "\n",
    "    # mention_count: The users that are mentioned within the tweet (e.g. \"@someuser\").\n",
    "    data_transformed['mention_count'] = data_origin['user_mentions'].apply(lambda x: 0 if pd.isna(x) else len(x.split(',')))\n",
    "\n",
    "    # url_exist: 1 or 0 to denote whether a tweet contains any URL\n",
    "    data_transformed['url_exist'] = (1 - data_origin['urls'].isna()).astype(int)\n",
    "\n",
    "    # url_count: The total number of URLs in a tweet\n",
    "    data_transformed['url_count'] = data_origin['urls'].apply(lambda x: 0 if pd.isna(x) else len(x.split(',')))\n",
    "\n",
    "    # hashtag_exist: 1 or 0 to denote whether a tweet contains any hashtag\n",
    "    data_transformed['hashtag_exist'] = (1 - data_origin['hashtags'].isna()).astype(int)\n",
    "\n",
    "    # hashtag_count: The total number of hashtags in a tweet\n",
    "    data_transformed['hashtag_count'] = data_origin['hashtags'].apply(lambda x: 0 if pd.isna(x) else len(x.split(',')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Extraction of time features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract time features\n",
    "def extract_time_features(data_origin, data_transformed):\n",
    "    print('extracting time features')\n",
    "    # timeseg： The time segment of a tweet {1...24} indicating when it is posted\n",
    "    data_transformed['timeseg'] = data_origin['timestamp'].apply(lambda x: datetime.fromtimestamp(x/1000).hour + 1) \n",
    "\n",
    "    # day_of_week: The value from {1...7} to indicate a day of the week\n",
    "    data_transformed['day_of_week'] = data_origin['timestamp'].apply(lambda x: datetime.fromtimestamp(x/1000).isoweekday())\n",
    "\n",
    "    # weekend： 1 or 0 to indicate whether a tweet is posted on a weekend or not\n",
    "    data_transformed['weekend'] = data_transformed['day_of_week'].apply(lambda x: 1 if (x == 6 or x == 7) else 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Extraction of text features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract text features\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "def get_setiment_score(sentence):\n",
    "    vs = analyzer.polarity_scores(sentence)\n",
    "    return vs['pos'], vs['neg'], vs['neu'], vs['compound']\n",
    "\n",
    "def extract_text_features(data_origin, data_transformed):\n",
    "    print('extracting text features')\n",
    "    # text length: The length of the text\n",
    "    data_transformed['text_length'] = data_origin['text'].str.len()\n",
    "\n",
    "    # tf_idf: Term Frequency and Inverse Term Frequency of the text\n",
    "    vectorizer = TfidfVectorizer(max_features=100, stop_words='english')\n",
    "    tf_idf = vectorizer.fit_transform(data_origin['text']).toarray()\n",
    "    # reduct the dimension of tf_idf result using svd\n",
    "    svd = TruncatedSVD(n_components=10)\n",
    "    tf_idf_reducted = svd.fit_transform(tf_idf)\n",
    "    print(svd.explained_variance_ratio_)\n",
    "    for i in range(tf_idf_reducted.shape[1]):\n",
    "        data_transformed['tf_idf_'+str(i)] = tf_idf_reducted[:,i]\n",
    "\n",
    "    # sentiment_pos, sentiment_neg, sentiment_neu, sentiment_comp: Scores for positive, negative, neutral, compound sentiments for a tweet\n",
    "    data_transformed['sentiment_pos'], data_transformed['sentiment_neg'], data_transformed['sentiment_neu'], data_transformed['sentiment_comp'] = zip(*data_origin['text'].apply(get_setiment_score)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract all features\n",
    "features = ['user_verified','user_statuses_count','user_followers_count','user_friends_count','ratio_friends_followers',\n",
    "           'mention_exist','mention_count', 'url_exist','url_count', 'hashtag_exist','hashtag_count',\n",
    "           'timeseg', 'weekend', 'day_of_week',\n",
    "           'text_length', 'sentiment_pos', 'sentiment_neg', 'sentiment_neu', 'sentiment_comp']\n",
    "def extract_features(data_origin, is_train_data):\n",
    "    data_transformed = pd.DataFrame(np.zeros((data_origin.shape[0], len(features))), index = data_origin.index, columns = features)\n",
    "    if is_train_data:\n",
    "        data_transformed['retweet_count'] = data_origin['retweet_count']\n",
    "    extract_user_features(data_origin, data_transformed)\n",
    "    extract_tweet_features(data_origin, data_transformed)\n",
    "    extract_time_features(data_origin, data_transformed)\n",
    "    extract_text_features(data_origin, data_transformed)\n",
    "    data_transformed.fillna(0)\n",
    "    return data_transformed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Extraction of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extracting features of evaluation data\n",
      "extracting user features\n",
      "extracting tweet features\n",
      "extracting time features\n",
      "extracting text features\n",
      "[0.07130282 0.05996944 0.04547115 0.02966212 0.02499426 0.02145453\n",
      " 0.01976273 0.01828619 0.01796008 0.01559779]\n",
      "writing transformed evaluation data into evaluation_transformed.csv\n",
      "extracting features of trainning data\n",
      "extracting user features\n",
      "extracting tweet features\n",
      "extracting time features\n",
      "extracting text features\n",
      "[0.07128467 0.06013182 0.04532428 0.02957303 0.0253767  0.02161874\n",
      " 0.01971663 0.01820126 0.01771515 0.01531939]\n",
      "writing transformed trainning data into train_transformed.csv\n"
     ]
    }
   ],
   "source": [
    "# Extract features of evaluation data\n",
    "X_evaluation = pd.read_csv(\"../data/evaluation.csv\", header=0, index_col=0)\n",
    "print('extracting features of evaluation data')\n",
    "X_evaluation_transformed = extract_features(X_evaluation, False)\n",
    "print('writing transformed evaluation data into evaluation_transformed.csv')\n",
    "X_evaluation_transformed.to_csv('../data/evaluation_transformed.csv',index_label='id')\n",
    "\n",
    "# Extract features of trainning data\n",
    "X_train = pd.read_csv(\"../data/train.csv\", header=0, index_col=0)\n",
    "print('extracting features of trainning data')\n",
    "X_train_transformed = extract_features(X_train, True)\n",
    "print('writing transformed trainning data into train_transformed.csv')\n",
    "X_train_transformed.to_csv('../data/train_transformed.csv',index_label='id')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
